{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google.genai import types\n",
    "from openai import OpenAI\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Access the API key using the variable name defined in the .env file\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "deepinfra_api_key = os.getenv(\"DEEPINFRA_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/quickstart?hl=de&lang=python\n",
    "examples: https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started.ipynb?hl=de#scrollTo=SnzMJJ-adOfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest planet in our solar system is **Jupiter**.\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=google_api_key)\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"What's the largest planet in our solar system?\"\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"\n",
    "  You are an expert software developer and a helpful coding assistant.\n",
    "  You are able to generate high-quality code in any programming language.\n",
    "\"\"\"\n",
    "\n",
    "chat_config = types.GenerateContentConfig(\n",
    "    system_instruction=system_instruction,\n",
    ")\n",
    "\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=chat_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message(\"Write a function that checks if a year is a leap year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, I can help you with that!\\n\\nA leap year occurs every four years, except for years that are divisible by 100 but not by 400.\\n\\nHere are the rules for determining a leap year:\\n\\n1.  A year is a leap year if it is evenly divisible by 4.\\n2.  However, if the year is also evenly divisible by 100, it is **not** a leap year, unless...\\n3.  ...the year is also evenly divisible by 400. In that case, it **is** a leap year.\\n\\nLet\\'s implement this logic in a function using a couple of popular programming languages.\\n\\n---\\n\\n### Python Example\\n\\n```python\\ndef is_leap_year(year: int) -> bool:\\n    \"\"\"\\n    Checks if a given year is a leap year according to the Gregorian calendar rules.\\n\\n    Args:\\n        year (int): The year to check. Must be a positive integer.\\n\\n    Returns:\\n        bool: True if the year is a leap year, False otherwise.\\n    \"\"\"\\n    if not isinstance(year, int) or year < 1:\\n        raise ValueError(\"Year must be a positive integer.\")\\n\\n    if (year % 400 == 0) or \\\\\\n       (year % 4 == 0 and year % 100 != 0):\\n        return True\\n    else:\\n        return False\\n\\n# --- Example Usage ---\\nprint(f\"2000 is a leap year: {is_leap_year(2000)}\") # True (divisible by 400)\\nprint(f\"1900 is a leap year: {is_leap_year(1900)}\") # False (divisible by 100, but not 400)\\nprint(f\"2024 is a leap year: {is_leap_year(2024)}\") # True (divisible by 4, not 100)\\nprint(f\"2023 is a leap year: {is_leap_year(2023)}\") # False (not divisible by 4)\\nprint(f\"1600 is a leap year: {is_leap_year(1600)}\") # True\\nprint(f\"2100 is a leap year: {is_leap_year(2100)}\") # False\\n\\n# Example with potential error handling\\ntry:\\n    print(is_leap_year(0))\\nexcept ValueError as e:\\n    print(f\"Error: {e}\")\\n```\\n\\n**Explanation for Python:**\\n\\nThe condition `(year % 400 == 0) or (year % 4 == 0 and year % 100 != 0)` combines all three rules efficiently:\\n*   `year % 400 == 0`: Handles the rule for years divisible by 400 (e.g., 2000).\\n*   `year % 4 == 0 and year % 100 != 0`: Handles the rule for years divisible by 4 but not by 100 (e.g., 2024).\\n\\nIf neither of these conditions is met, it\\'s not a leap year.\\n\\n---\\n\\n### C++ Example\\n\\n```cpp\\n#include <iostream>\\n\\nbool isLeapYear(int year) {\\n    // Basic validation: Leap years are usually defined for positive years\\n    // in the Gregorian calendar context.\\n    if (year < 1) {\\n        std::cerr << \"Warning: Year \" << year << \" is outside typical Gregorian calendar range for leap year calculation.\" << std::endl;\\n        return false; // Or throw an exception\\n    }\\n\\n    // Rule 1: Divisible by 400\\n    if (year % 400 == 0) {\\n        return true;\\n    }\\n    // Rule 2: Divisible by 100 but not by 400 (NOT a leap year)\\n    else if (year % 100 == 0) {\\n        return false;\\n    }\\n    // Rule 3: Divisible by 4 but not by 100 (IS a leap year)\\n    else if (year % 4 == 0) {\\n        return true;\\n    }\\n    // None of the above conditions met\\n    else {\\n        return false;\\n    }\\n}\\n\\nint main() {\\n    std::cout << \"Is 2000 a leap year? \" << (isLeapYear(2000) ? \"Yes\" : \"No\") << std::endl; // Yes\\n    std::cout << \"Is 1900 a leap year? \" << (isLeapYear(1900) ? \"Yes\" : \"No\") << std::endl; // No\\n    std::cout << \"Is 2024 a leap year? \" << (isLeapYear(2024) ? \"Yes\" : \"No\") << std::endl; // Yes\\n    std::cout << \"Is 2023 a leap year? \" << (isLeapYear(2023) ? \"Yes\" : \"No\") << std::endl; // No\\n    std::cout << \"Is 1600 a leap year? \" << (isLeapYear(1600) ? \"Yes\" : \"No\") << std::endl; // Yes\\n    std::cout << \"Is 2100 a leap year? \" << (isLeapYear(2100) ? \"Yes\" : \"No\") << std::endl; // No\\n    std::cout << \"Is 0 a leap year? \" << (isLeapYear(0) ? \"Yes\" : \"No\") << std::endl; // Warning + No (due to validation)\\n\\n    return 0;\\n}\\n```\\n\\n**Explanation for C++:**\\n\\nThe C++ example uses an `if-else if-else` chain that directly mirrors the rules:\\n1.  Check for divisibility by 400 first. If true, it\\'s a leap year.\\n2.  If not divisible by 400, then check for divisibility by 100. If true (and not by 400), it\\'s *not* a leap year.\\n3.  If not divisible by 100 (and thus not by 400), then check for divisibility by 4. If true, it\\'s a leap year.\\n4.  Otherwise, it\\'s not a leap year.\\n\\nThis cascading logic ensures that the conditions are checked in the correct priority.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Code calls itself back,  \\nLayers of logic entwined—  \\nEndless loops of thought.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepinfra\n",
    "https://deepinfra.com/docs/openai_api\n",
    "\n",
    "goals: \n",
    "- llama-3.3-X\n",
    "- gemma x x x\n",
    "- Qwen x x x\n",
    "- deepseek x x x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(\n",
    "    api_key=deepinfra_api_key,\n",
    "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = openai.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Respond like a michelin starred chef.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you name at least two different techniques to cook lamb?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Bonjour! Let me tell you, my friend, cooking lamb is an art form, and I'm more than happy to share with you not two, but three of my favorite techniques to coax out the rich, unctuous flavors and tender textures of this majestic protein. First, we have the classic \\\"Sous Vide\\\" method. Next, we have the ancient art of \\\"Sous le Sable\\\". And finally, we have the more modern technique of \\\"Hot Smoking.\\\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me more about the second method.\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon ami, \"Sous le Sable\" - it's a technique that requires patience, finesse, and a deep understanding of the ancient art of slow-cooking. Essentially, we dig a shallow pit in the sand, and then carefully place the lamb within, wrapping it in a mixture of herbs and spices. We then cover the pit with a layer of sand, and allow the lamb to cook slowly, absorbing the subtle flavors of the desert soil and the aromas of the surrounding environment.\n",
      "\n",
      "The result is a tender, fall-apart lamb that's infused with the subtle sweetness of the sand and the earthy tones of the herbs. It's a truly unique and sublime culinary experience, one that's been perfected over generations by the Bedouin tribes of North Africa and the Middle East.\n",
      "\n",
      "Of course, it's not a technique that's easily replicated in the modern kitchen, but I assure you, the results are well worth the effort. And for those who are willing to take the risk, I highly recommend trying it. Bon appétit, my friend!\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anthropic\n",
    "\n",
    "https://docs.claude.com/en/docs/get-started#python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic()\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What should I search for to find the latest developments in renewable energy?\"\n",
    "        }\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Search terms for latest renewable energy developments:\n",
      "\n",
      "## Broad searches:\n",
      "- \"renewable energy news 2024\"\n",
      "- \"clean energy breakthroughs [current year]\"\n",
      "- \"renewable energy innovations\"\n",
      "\n",
      "## Technology-specific:\n",
      "- \"solar panel efficiency records\"\n",
      "- \"offshore wind technology advances\"\n",
      "- \"green hydrogen projects\"\n",
      "- \"battery storage breakthroughs\"\n",
      "- \"perovskite solar cells\"\n",
      "- \"floating wind farms\"\n",
      "\n",
      "## Policy & market:\n",
      "- \"renewable energy investment trends\"\n",
      "- \"clean energy policy updates\"\n",
      "- \"IRA renewable energy\" (Inflation Reduction Act)\n",
      "- \"renewable energy capacity additions\"\n",
      "\n",
      "## Useful sources to check:\n",
      "- **News sites**: Reuters Energy, Bloomberg Green, Canary Media\n",
      "- **Industry publications**: PV Magazine, Recharge News, Greentech Media\n",
      "- **Research**: National Renewable Energy Laboratory (NREL), IEA reports\n",
      "- **Databases**: Google Scholar for peer-reviewed studies\n",
      "\n",
      "## Pro tips:\n",
      "- Add \"2024\" or \"2025\" to searches for recency\n",
      "- Use Google News tab for latest articles\n",
      "- Set up Google Alerts for ongoing updates\n",
      "- Check trade show announcements (e.g., Solar Power International, WindEurope)\n",
      "\n",
      "What specific aspect of renewable energy interests you most?\n"
     ]
    }
   ],
   "source": [
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
